{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "454d802d65270b418e4d05e9cfd3093edba6cd25"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d519f87e986a4caff405792bdf5f88af064dd4b8"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "40c4ad4e03ff3701bacf112e0cfb79321f0456e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:(913000, 4), Test shape:(45000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store  item  sales\n",
       "0 2013-01-01      1     1     13\n",
       "1 2013-01-02      1     1     11\n",
       "2 2013-01-03      1     1     14\n",
       "3 2013-01-04      1     1     13\n",
       "4 2013-01-05      1     1     10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "train = pd.read_csv('input/train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('input/test.csv', parse_dates=['date'])\n",
    "sample_sub = pd.read_csv('input/sample_submission.csv')\n",
    "print('Train shape:{}, Test shape:{}'.format(train.shape, test.shape))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03f82077e80bba187f3ff0d0cf58ba973c13c7ef"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "49f8496f37589f16e61d1f2aa965412a14ec7069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined df shape:(958000, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating train & test\n",
    "train['train_or_test'] = 'train'\n",
    "test['train_or_test'] = 'test'\n",
    "df = pd.concat([train,test], sort=False)\n",
    "print('Combined df shape:{}'.format(df.shape))\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2c63fcf7e65e09b015f0d5aced7a2e0e009daf2"
   },
   "source": [
    "### Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "424bf991b29ea359b007bcd8c2a8cdf054c1cc1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>id</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store  item  sales train_or_test  id  dayofmonth  dayofyear  \\\n",
       "0 2013-01-01      1     1   13.0         train NaN           1          1   \n",
       "1 2013-01-02      1     1   11.0         train NaN           2          2   \n",
       "2 2013-01-03      1     1   14.0         train NaN           3          3   \n",
       "3 2013-01-04      1     1   13.0         train NaN           4          4   \n",
       "4 2013-01-05      1     1   10.0         train NaN           5          5   \n",
       "\n",
       "   dayofweek  month  year  weekofyear  is_month_start  is_month_end  \n",
       "0          1      1  2013           1               1             0  \n",
       "1          2      1  2013           1               0             0  \n",
       "2          3      1  2013           1               0             0  \n",
       "3          4      1  2013           1               0             0  \n",
       "4          5      1  2013           1               0             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting date features\n",
    "df['dayofmonth'] = df.date.dt.day\n",
    "df['dayofyear'] = df.date.dt.dayofyear\n",
    "df['dayofweek'] = df.date.dt.dayofweek\n",
    "df['month'] = df.date.dt.month\n",
    "df['year'] = df.date.dt.year\n",
    "df['weekofyear'] = df.date.dt.weekofyear\n",
    "df['is_month_start'] = (df.date.dt.is_month_start).astype(int)\n",
    "df['is_month_end'] = (df.date.dt.is_month_end).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "328bae42ea8aa58ebc512be340c55d3f05918b94"
   },
   "outputs": [],
   "source": [
    "# Sorting the dataframe by store then item then date\n",
    "#df.sort_values(by=['store','item','month','dayofweek'], axis=0, inplace=True)\n",
    "df.sort_values(by=['store','item','date'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "019db2cf8e367672bb2339330767de1b70fae4cd"
   },
   "source": [
    "### Monthwise aggregated sales values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "28475aa2a93911d3149c2c38f369b22c12ab58b3"
   },
   "outputs": [],
   "source": [
    "def create_sales_agg_monthwise_features(df, gpby_cols, target_col, agg_funcs):\n",
    "    '''\n",
    "    Creates various sales agg features with given agg functions  \n",
    "    '''\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    newdf = df[gpby_cols].drop_duplicates().reset_index(drop=True)\n",
    "    for agg_name, agg_func in agg_funcs.items():\n",
    "        aggdf = gpby[target_col].agg(agg_func).reset_index()\n",
    "        aggdf.rename(columns={target_col:target_col+'_'+agg_name}, inplace=True)\n",
    "        newdf = newdf.merge(aggdf, on=gpby_cols, how='left')\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3caa2627c7c33bc8c273daf3ba87fada453a5ca"
   },
   "source": [
    "### Features constructed from previous sales values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "79559cff98ede8c16cff2f7f7d575436112488ae"
   },
   "outputs": [],
   "source": [
    "# Creating sales lag features\n",
    "def create_sales_lag_feats(df, gpby_cols, target_col, lags):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for i in lags:\n",
    "        df['_'.join([target_col, 'lag', str(i)])] = \\\n",
    "                gpby[target_col].shift(i).values + np.random.normal(scale=1.6, size=(len(df),))\n",
    "    return df\n",
    "\n",
    "# Creating sales rolling mean features\n",
    "def create_sales_rmean_feats(df, gpby_cols, target_col, windows, min_periods=2, \n",
    "                             shift=1, win_type=None):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for w in windows:\n",
    "        df['_'.join([target_col, 'rmean', str(w)])] = \\\n",
    "            gpby[target_col].shift(shift).rolling(window=w, \n",
    "                                                  min_periods=min_periods,\n",
    "                                                  win_type=win_type).mean().values +\\\n",
    "            np.random.normal(scale=1.6, size=(len(df),))\n",
    "    return df\n",
    "\n",
    "# Creating sales rolling median features\n",
    "def create_sales_rmed_feats(df, gpby_cols, target_col, windows, min_periods=2, \n",
    "                            shift=1, win_type=None):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for w in windows:\n",
    "        df['_'.join([target_col, 'rmed', str(w)])] = \\\n",
    "            gpby[target_col].shift(shift).rolling(window=w, \n",
    "                                                  min_periods=min_periods,\n",
    "                                                  win_type=win_type).median().values +\\\n",
    "            np.random.normal(scale=1.6, size=(len(df),))\n",
    "    return df\n",
    "\n",
    "# Creating sales exponentially weighted mean features\n",
    "def create_sales_ewm_feats(df, gpby_cols, target_col, alpha=[0.9], shift=[1]):\n",
    "    gpby = df.groupby(gpby_cols)\n",
    "    for a in alpha:\n",
    "        for s in shift:\n",
    "            df['_'.join([target_col, 'lag', str(s), 'ewm', str(a)])] = \\\n",
    "                gpby[target_col].shift(s).ewm(alpha=a).mean().values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1abfbefd0f70daebfdce943d4a292d8a8d7f71be"
   },
   "source": [
    "### OHE of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "ee278af552f8180d1d087979104995d89f5736ff"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, ohe_cols=['store','item','dayofmonth','dayofweek','month','weekofyear']):\n",
    "    '''\n",
    "    One-Hot Encoder function\n",
    "    '''\n",
    "    print('Creating OHE features..\\nOld df shape:{}'.format(df.shape))\n",
    "    df = pd.get_dummies(df, columns=ohe_cols)\n",
    "    print('New df shape:{}'.format(df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69d6af2b8e69c797cc27b887c0e87050ec18870d"
   },
   "source": [
    "### Log Sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "9075af279047a4b90ef6d2bb96c268058621452b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>id</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391707</th>\n",
       "      <td>2015-08-02</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>4.521789</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403581</th>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  store  item     sales train_or_test  id  dayofmonth  \\\n",
       "391707 2015-08-02      5    22  4.521789         train NaN           2   \n",
       "403581 2013-02-05      2    23  3.496508         train NaN           5   \n",
       "\n",
       "        dayofyear  dayofweek  month  year  weekofyear  is_month_start  \\\n",
       "391707        214          6      8  2015          31               0   \n",
       "403581         36          1      2  2013           6               0   \n",
       "\n",
       "        is_month_end  \n",
       "391707             0  \n",
       "403581             0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting sales to log(1+sales)\n",
    "df['sales'] = np.log1p(df.sales.values)\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "06b09956138bd3ef34009606aba6cf6f5065ae02"
   },
   "source": [
    "## Time-based Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "e4d32958c67c166e1fe59b73bbe5b674c7335c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (730500, 14)\n",
      "Validation shape: (45000, 14)\n",
      "No train shape: (137500, 14)\n",
      "Test shape: (45000, 14)\n"
     ]
    }
   ],
   "source": [
    "# For validation \n",
    "# We can choose last 3 months of training period(Oct, Nov, Dec 2017) as our validation set to gauge the performance of the model.\n",
    "# OR to keep months also identical to test set we can choose period (Jan, Feb, Mar 2017) as the validation set.\n",
    "# Here we will go with the latter choice.\n",
    "masked_series = (df.year==2017) & (df.month.isin([1,2,3]))\n",
    "masked_series2 = (df.year==2017) & (~(df.month.isin([1,2,3])))\n",
    "df.loc[(masked_series), 'train_or_test'] = 'val'\n",
    "df.loc[(masked_series2), 'train_or_test'] = 'no_train'\n",
    "print('Train shape: {}'.format(df.loc[df.train_or_test=='train',:].shape))\n",
    "print('Validation shape: {}'.format(df.loc[df.train_or_test=='val',:].shape))\n",
    "print('No train shape: {}'.format(df.loc[df.train_or_test=='no_train',:].shape))\n",
    "print('Test shape: {}'.format(df.loc[df.train_or_test=='test',:].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69c7c13414eb865e98745489ab36bfb3d0b98a07"
   },
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "3e5de9c3d49c9a95887a8e7e9d110e2e72851594"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cazti\\Anaconda2\\envs\\synx\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\cazti\\Anaconda2\\envs\\synx\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\cazti\\Anaconda2\\envs\\synx\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\cazti\\Anaconda2\\envs\\synx\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating OHE features..\n",
      "Old df shape:(775500, 86)\n",
      "New df shape:(775500, 161)\n",
      "Train shape:(730500, 161), Val shape:(45000, 161)\n"
     ]
    }
   ],
   "source": [
    "# Converting sales of validation period to nan so as to resemble test period\n",
    "train = df.loc[df.train_or_test.isin(['train','val']), :]\n",
    "Y_val = train.loc[train.train_or_test=='val', 'sales'].values.reshape((-1))\n",
    "Y_train = train.loc[train.train_or_test=='train', 'sales'].values.reshape((-1))\n",
    "train.loc[train.train_or_test=='val', 'sales'] = np.nan\n",
    "\n",
    "# # Creating sales lag, rolling mean, rolling median, ohe features of the above train set\n",
    "train = create_sales_lag_feats(train, gpby_cols=['store','item'], target_col='sales', \n",
    "                               lags=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "train = create_sales_rmean_feats(train, gpby_cols=['store','item'], \n",
    "                                 target_col='sales', windows=[364,546], \n",
    "                                 min_periods=10, win_type='triang') #98,119,91,182,\n",
    "\n",
    "# # train = create_sales_rmed_feats(train, gpby_cols=['store','item'], \n",
    "# #                                 target_col='sales', windows=[364,546], \n",
    "# #                                 min_periods=10, win_type=None) #98,119,91,182,\n",
    "\n",
    "train = create_sales_ewm_feats(train, gpby_cols=['store','item'], \n",
    "                               target_col='sales', \n",
    "                               alpha=[0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \n",
    "                               shift=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "# # Creating sales monthwise aggregated values\n",
    "# agg_df = create_sales_agg_monthwise_features(df.loc[df.train_or_test=='train', :], \n",
    "#                                              gpby_cols=['store','item','month'], \n",
    "#                                              target_col='sales', \n",
    "#                                              agg_funcs={'mean':np.mean, \n",
    "#                                              'median':np.median, 'max':np.max, \n",
    "#                                              'min':np.min, 'std':np.std})\n",
    "\n",
    "# # Joining agg_df with train\n",
    "# train = train.merge(agg_df, on=['store','item','month'], how='left')\n",
    "\n",
    "# One-Hot Encoding \n",
    "train = one_hot_encoder(train, ohe_cols=['store','item','dayofweek','month']) \n",
    "#,'dayofmonth','weekofyear'\n",
    "\n",
    "# Final train and val datasets\n",
    "val = train.loc[train.train_or_test=='val', :]\n",
    "train = train.loc[train.train_or_test=='train', :]\n",
    "print('Train shape:{}, Val shape:{}'.format(train.shape, val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a7732144f23f0a99b5846ca8315455b84f1ca46e"
   },
   "source": [
    "## LightGBM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "17982e472879d213fd8e771c3156c89cdd954388"
   },
   "source": [
    "### Training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "3c33f479d52628e200d2905e7c78ba43238be2a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training features: 156 \n",
      "And they are:['dayofmonth', 'dayofyear', 'weekofyear', 'is_month_start', 'is_month_end', 'sales_lag_91', 'sales_lag_98', 'sales_lag_105', 'sales_lag_112', 'sales_lag_119', 'sales_lag_126', 'sales_lag_182', 'sales_lag_364', 'sales_lag_546', 'sales_lag_728', 'sales_rmean_364', 'sales_rmean_546', 'sales_lag_91_ewm_0.95', 'sales_lag_98_ewm_0.95', 'sales_lag_105_ewm_0.95', 'sales_lag_112_ewm_0.95', 'sales_lag_119_ewm_0.95', 'sales_lag_126_ewm_0.95', 'sales_lag_182_ewm_0.95', 'sales_lag_364_ewm_0.95', 'sales_lag_546_ewm_0.95', 'sales_lag_728_ewm_0.95', 'sales_lag_91_ewm_0.9', 'sales_lag_98_ewm_0.9', 'sales_lag_105_ewm_0.9', 'sales_lag_112_ewm_0.9', 'sales_lag_119_ewm_0.9', 'sales_lag_126_ewm_0.9', 'sales_lag_182_ewm_0.9', 'sales_lag_364_ewm_0.9', 'sales_lag_546_ewm_0.9', 'sales_lag_728_ewm_0.9', 'sales_lag_91_ewm_0.8', 'sales_lag_98_ewm_0.8', 'sales_lag_105_ewm_0.8', 'sales_lag_112_ewm_0.8', 'sales_lag_119_ewm_0.8', 'sales_lag_126_ewm_0.8', 'sales_lag_182_ewm_0.8', 'sales_lag_364_ewm_0.8', 'sales_lag_546_ewm_0.8', 'sales_lag_728_ewm_0.8', 'sales_lag_91_ewm_0.7', 'sales_lag_98_ewm_0.7', 'sales_lag_105_ewm_0.7', 'sales_lag_112_ewm_0.7', 'sales_lag_119_ewm_0.7', 'sales_lag_126_ewm_0.7', 'sales_lag_182_ewm_0.7', 'sales_lag_364_ewm_0.7', 'sales_lag_546_ewm_0.7', 'sales_lag_728_ewm_0.7', 'sales_lag_91_ewm_0.6', 'sales_lag_98_ewm_0.6', 'sales_lag_105_ewm_0.6', 'sales_lag_112_ewm_0.6', 'sales_lag_119_ewm_0.6', 'sales_lag_126_ewm_0.6', 'sales_lag_182_ewm_0.6', 'sales_lag_364_ewm_0.6', 'sales_lag_546_ewm_0.6', 'sales_lag_728_ewm_0.6', 'sales_lag_91_ewm_0.5', 'sales_lag_98_ewm_0.5', 'sales_lag_105_ewm_0.5', 'sales_lag_112_ewm_0.5', 'sales_lag_119_ewm_0.5', 'sales_lag_126_ewm_0.5', 'sales_lag_182_ewm_0.5', 'sales_lag_364_ewm_0.5', 'sales_lag_546_ewm_0.5', 'sales_lag_728_ewm_0.5', 'store_1', 'store_2', 'store_3', 'store_4', 'store_5', 'store_6', 'store_7', 'store_8', 'store_9', 'store_10', 'item_1', 'item_2', 'item_3', 'item_4', 'item_5', 'item_6', 'item_7', 'item_8', 'item_9', 'item_10', 'item_11', 'item_12', 'item_13', 'item_14', 'item_15', 'item_16', 'item_17', 'item_18', 'item_19', 'item_20', 'item_21', 'item_22', 'item_23', 'item_24', 'item_25', 'item_26', 'item_27', 'item_28', 'item_29', 'item_30', 'item_31', 'item_32', 'item_33', 'item_34', 'item_35', 'item_36', 'item_37', 'item_38', 'item_39', 'item_40', 'item_41', 'item_42', 'item_43', 'item_44', 'item_45', 'item_46', 'item_47', 'item_48', 'item_49', 'item_50', 'dayofweek_0', 'dayofweek_1', 'dayofweek_2', 'dayofweek_3', 'dayofweek_4', 'dayofweek_5', 'dayofweek_6', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12']\n"
     ]
    }
   ],
   "source": [
    "avoid_cols = ['date', 'sales', 'train_or_test', 'id', 'year']\n",
    "cols = [col for col in train.columns if col not in avoid_cols]\n",
    "print('No of training features: {} \\nAnd they are:{}'.format(len(cols), cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "de085b7a91c27ff28248735e6c1387f432131644"
   },
   "outputs": [],
   "source": [
    "def smape(preds, target):\n",
    "    '''\n",
    "    Function to calculate SMAPE\n",
    "    '''\n",
    "    n = len(preds)\n",
    "    masked_arr = ~((preds==0)&(target==0))\n",
    "    preds, target = preds[masked_arr], target[masked_arr]\n",
    "    num = np.abs(preds-target)\n",
    "    denom = np.abs(preds)+np.abs(target)\n",
    "    smape_val = (200*np.sum(num/denom))/n\n",
    "    return smape_val\n",
    "\n",
    "def lgbm_smape(preds, train_data):\n",
    "    '''\n",
    "    Custom Evaluation Function for LGBM\n",
    "    '''\n",
    "    labels = train_data.get_label()\n",
    "    smape_val = smape(np.expm1(preds), np.expm1(labels))\n",
    "    return 'SMAPE', smape_val, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "bebd7beef960cb6bcdf39a66ce1f5bb09ec23e04"
   },
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "lgb_params = {'task':'train', 'boosting_type':'gbdt', 'objective':'regression', \n",
    "              'metric': {'mae'}, 'num_leaves': 10, 'learning_rate': 0.02, \n",
    "              'feature_fraction': 0.8, 'max_depth': 5, 'verbose': 0, \n",
    "              'num_boost_round':15000, 'early_stopping_rounds':200, 'nthread':-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "0f6c0b39b78177a733641da24c42abe18c2a33d9"
   },
   "outputs": [],
   "source": [
    "# Creating lgbtrain & lgbval\n",
    "lgbtrain = lgb.Dataset(data=train.loc[:,cols].values, label=Y_train, \n",
    "                       feature_name=cols)\n",
    "lgbval = lgb.Dataset(data=val.loc[:,cols].values, label=Y_val, \n",
    "                     reference=lgbtrain, feature_name=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "2bf8adfe7d434402acaaa0b03399937f24dcd007"
   },
   "outputs": [],
   "source": [
    "def lgb_validation(params, lgbtrain, lgbval, X_val, Y_val, verbose_eval):\n",
    "    t0 = time.time()\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgbtrain, num_boost_round=params['num_boost_round'], \n",
    "                      valid_sets=[lgbtrain, lgbval], feval=lgbm_smape, \n",
    "                      early_stopping_rounds=params['early_stopping_rounds'], \n",
    "                      evals_result=evals_result, verbose_eval=verbose_eval)\n",
    "    print(model.best_iteration)\n",
    "    print('Total time taken to build the model: ', (time.time()-t0)/60, 'minutes!!')\n",
    "    pred_Y_val = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    pred_Y_val = np.expm1(pred_Y_val)\n",
    "    Y_val = np.expm1(Y_val)\n",
    "    val_df = pd.DataFrame(columns=['true_Y_val','pred_Y_val'])\n",
    "    val_df['pred_Y_val'] = pred_Y_val\n",
    "    val_df['true_Y_val'] = Y_val\n",
    "    print(val_df.shape)\n",
    "    print(val_df.sample(5))\n",
    "    print('SMAPE for validation data is:{}'.format(smape(pred_Y_val, Y_val)))\n",
    "    return model, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "21eb1034ea7d6b6523d21aceb98849c9a1f29ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's l1: 0.1467\ttraining's SMAPE: 15.0186\tvalid_1's l1: 0.14078\tvalid_1's SMAPE: 14.4538\n",
      "[1000]\ttraining's l1: 0.137887\ttraining's SMAPE: 14.1391\tvalid_1's l1: 0.138398\tvalid_1's SMAPE: 14.2159\n",
      "[1500]\ttraining's l1: 0.133905\ttraining's SMAPE: 13.7381\tvalid_1's l1: 0.136968\tvalid_1's SMAPE: 14.0724\n",
      "[2000]\ttraining's l1: 0.131763\ttraining's SMAPE: 13.5221\tvalid_1's l1: 0.135874\tvalid_1's SMAPE: 13.9624\n",
      "[2500]\ttraining's l1: 0.130434\ttraining's SMAPE: 13.388\tvalid_1's l1: 0.135129\tvalid_1's SMAPE: 13.8873\n",
      "[3000]\ttraining's l1: 0.129592\ttraining's SMAPE: 13.3031\tvalid_1's l1: 0.134586\tvalid_1's SMAPE: 13.8326\n",
      "[3500]\ttraining's l1: 0.12898\ttraining's SMAPE: 13.2412\tvalid_1's l1: 0.134207\tvalid_1's SMAPE: 13.7944\n",
      "[4000]\ttraining's l1: 0.128515\ttraining's SMAPE: 13.1942\tvalid_1's l1: 0.133934\tvalid_1's SMAPE: 13.767\n",
      "[4500]\ttraining's l1: 0.128112\ttraining's SMAPE: 13.1535\tvalid_1's l1: 0.1337\tvalid_1's SMAPE: 13.7434\n",
      "[5000]\ttraining's l1: 0.127769\ttraining's SMAPE: 13.1187\tvalid_1's l1: 0.133501\tvalid_1's SMAPE: 13.7234\n",
      "[5500]\ttraining's l1: 0.127455\ttraining's SMAPE: 13.0869\tvalid_1's l1: 0.133334\tvalid_1's SMAPE: 13.7066\n",
      "[6000]\ttraining's l1: 0.127172\ttraining's SMAPE: 13.0583\tvalid_1's l1: 0.133173\tvalid_1's SMAPE: 13.6904\n",
      "[6500]\ttraining's l1: 0.126917\ttraining's SMAPE: 13.0323\tvalid_1's l1: 0.133055\tvalid_1's SMAPE: 13.6786\n",
      "[7000]\ttraining's l1: 0.126667\ttraining's SMAPE: 13.007\tvalid_1's l1: 0.132931\tvalid_1's SMAPE: 13.6662\n",
      "[7500]\ttraining's l1: 0.126435\ttraining's SMAPE: 12.9835\tvalid_1's l1: 0.132827\tvalid_1's SMAPE: 13.6558\n",
      "[8000]\ttraining's l1: 0.126214\ttraining's SMAPE: 12.961\tvalid_1's l1: 0.132747\tvalid_1's SMAPE: 13.6477\n",
      "[8500]\ttraining's l1: 0.126011\ttraining's SMAPE: 12.9404\tvalid_1's l1: 0.132673\tvalid_1's SMAPE: 13.6403\n",
      "[9000]\ttraining's l1: 0.125819\ttraining's SMAPE: 12.921\tvalid_1's l1: 0.132607\tvalid_1's SMAPE: 13.6337\n",
      "[9500]\ttraining's l1: 0.125629\ttraining's SMAPE: 12.9016\tvalid_1's l1: 0.132555\tvalid_1's SMAPE: 13.6285\n",
      "[10000]\ttraining's l1: 0.125451\ttraining's SMAPE: 12.8835\tvalid_1's l1: 0.132494\tvalid_1's SMAPE: 13.6223\n",
      "[10500]\ttraining's l1: 0.125274\ttraining's SMAPE: 12.8655\tvalid_1's l1: 0.132442\tvalid_1's SMAPE: 13.617\n",
      "[11000]\ttraining's l1: 0.125107\ttraining's SMAPE: 12.8485\tvalid_1's l1: 0.132397\tvalid_1's SMAPE: 13.6125\n",
      "[11500]\ttraining's l1: 0.124941\ttraining's SMAPE: 12.8316\tvalid_1's l1: 0.132358\tvalid_1's SMAPE: 13.6087\n",
      "[12000]\ttraining's l1: 0.124782\ttraining's SMAPE: 12.8154\tvalid_1's l1: 0.13231\tvalid_1's SMAPE: 13.6039\n",
      "[12500]\ttraining's l1: 0.12462\ttraining's SMAPE: 12.799\tvalid_1's l1: 0.132261\tvalid_1's SMAPE: 13.599\n",
      "[13000]\ttraining's l1: 0.124468\ttraining's SMAPE: 12.7835\tvalid_1's l1: 0.132238\tvalid_1's SMAPE: 13.5966\n",
      "[13500]\ttraining's l1: 0.124316\ttraining's SMAPE: 12.7679\tvalid_1's l1: 0.132205\tvalid_1's SMAPE: 13.5934\n",
      "[14000]\ttraining's l1: 0.124165\ttraining's SMAPE: 12.7525\tvalid_1's l1: 0.13219\tvalid_1's SMAPE: 13.5919\n",
      "[14500]\ttraining's l1: 0.124017\ttraining's SMAPE: 12.7375\tvalid_1's l1: 0.132155\tvalid_1's SMAPE: 13.5884\n",
      "[15000]\ttraining's l1: 0.123867\ttraining's SMAPE: 12.7222\tvalid_1's l1: 0.132128\tvalid_1's SMAPE: 13.5858\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[15000]\ttraining's l1: 0.123867\ttraining's SMAPE: 12.7222\tvalid_1's l1: 0.132128\tvalid_1's SMAPE: 13.5858\n",
      "15000\n",
      "Total time taken to build the model:  92.60978116194407 minutes!!\n",
      "(45000, 2)\n",
      "       true_Y_val  pred_Y_val\n",
      "25517        19.0   16.223687\n",
      "31077        34.0   33.773728\n",
      "41553        81.0   92.002763\n",
      "20922        52.0   53.056888\n",
      "31327        24.0   17.388711\n",
      "SMAPE for validation data is:13.585755706186962\n"
     ]
    }
   ],
   "source": [
    "# Training lightgbm model and validating\n",
    "model, val_df = lgb_validation(lgb_params, lgbtrain, lgbval, val.loc[:,cols].values, \n",
    "                               Y_val, verbose_eval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "d9f60a5bce135813adf2ad8524ff72a67f72fb7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features importance...\n",
      "Top 25 features:\n",
      "                     feature  split       gain\n",
      "67     sales_lag_91_ewm_0.5   2739  27.799887\n",
      "57     sales_lag_91_ewm_0.6   1447  11.682958\n",
      "74    sales_lag_364_ewm_0.5   3313   7.573448\n",
      "1                 dayofyear   6125   7.563541\n",
      "5              sales_lag_91   3770   4.797943\n",
      "37     sales_lag_91_ewm_0.8   1547   3.228566\n",
      "64    sales_lag_364_ewm_0.6   1605   2.809390\n",
      "18    sales_lag_98_ewm_0.95   2467   2.613903\n",
      "28     sales_lag_98_ewm_0.9   1087   2.400444\n",
      "38     sales_lag_98_ewm_0.8    754   2.343548\n",
      "47     sales_lag_91_ewm_0.7   1545   2.105054\n",
      "2                weekofyear   2716   2.008840\n",
      "68     sales_lag_98_ewm_0.5   2425   1.967989\n",
      "6              sales_lag_98   3012   1.450472\n",
      "29    sales_lag_105_ewm_0.9    746   1.390890\n",
      "12            sales_lag_364   2696   1.346486\n",
      "54    sales_lag_364_ewm_0.7   1299   1.329591\n",
      "19   sales_lag_105_ewm_0.95   1799   1.272137\n",
      "20   sales_lag_112_ewm_0.95   1301   1.117175\n",
      "137             dayofweek_0   1645   1.007992\n",
      "155                month_12    620   0.844342\n",
      "48     sales_lag_98_ewm_0.7    763   0.837724\n",
      "17    sales_lag_91_ewm_0.95   2775   0.829139\n",
      "39    sales_lag_105_ewm_0.8    675   0.528914\n",
      "148                 month_5    208   0.468143\n"
     ]
    }
   ],
   "source": [
    "# Let's see top 25 features as identified by the lightgbm model.\n",
    "print(\"Features importance...\")\n",
    "gain = model.feature_importance('gain')\n",
    "feat_imp = pd.DataFrame({'feature':model.feature_name(), \n",
    "                         'split':model.feature_importance('split'), \n",
    "                         'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "print('Top 25 features:\\n', feat_imp.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70a1432509985f18bdb6dd1535838db297a22658"
   },
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "a8781fd8f0fb9e98559a2c4f99519fc91c633e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating OHE features..\n",
      "Old df shape:(958000, 86)\n",
      "New df shape:(958000, 161)\n",
      "Train shape:(913000, 161), Test shape:(45000, 161)\n"
     ]
    }
   ],
   "source": [
    "# Creating sales lag, rolling mean, rolling median, ohe features of the above train set\n",
    "df_whole = create_sales_lag_feats(df, gpby_cols=['store','item'], target_col='sales', \n",
    "                                  lags=[91,98,105,112,119,126,182,364,546,728])\n",
    "df_whole = create_sales_rmean_feats(df_whole, gpby_cols=['store','item'], \n",
    "                                    target_col='sales', windows=[364,546], \n",
    "                                    min_periods=10, win_type='triang')\n",
    "# df = create_sales_rmed_feats(df, gpby_cols=['store','item'], target_col='sales', \n",
    "#                              windows=[364,546], min_periods=2) #98,119,\n",
    "df_whole = create_sales_ewm_feats(df_whole, gpby_cols=['store','item'], target_col='sales', \n",
    "                                  alpha=[0.95, 0.9, 0.8, 0.7, 0.6, 0.5], \n",
    "                                  shift=[91,98,105,112,119,126,182,364,546,728])\n",
    "\n",
    "# # Creating sales monthwise aggregated values\n",
    "# agg_df = create_sales_agg_monthwise_features(df.loc[~(df.train_or_test=='test'), :], \n",
    "#                                              gpby_cols=['store','item','month'], \n",
    "#                                              target_col='sales', \n",
    "#                                              agg_funcs={'mean':np.mean, \n",
    "#                                              'median':np.median, 'max':np.max, \n",
    "#                                              'min':np.min, 'std':np.std})\n",
    "\n",
    "# # Joining agg_df with df\n",
    "# df = df.merge(agg_df, on=['store','item','month'], how='left')\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_whole = one_hot_encoder(df_whole, ohe_cols=['store','item','dayofweek','month']) \n",
    "#'dayofmonth',,'weekofyear'\n",
    "\n",
    "# Final train and test datasets\n",
    "test = df_whole.loc[df_whole.train_or_test=='test', :]\n",
    "train = df_whole.loc[~(df_whole.train_or_test=='test'), :]\n",
    "print('Train shape:{}, Test shape:{}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "9d93caa77885762a3e6729341414f54c1c1d0675"
   },
   "outputs": [],
   "source": [
    "# LightGBM dataset\n",
    "lgbtrain_all = lgb.Dataset(data=train.loc[:,cols].values, \n",
    "                           label=train.loc[:,'sales'].values.reshape((-1,)), \n",
    "                           feature_name=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "051cf13823f8edf3810e88016c90db5c14054ef2"
   },
   "outputs": [],
   "source": [
    "def lgb_train(params, lgbtrain_all, X_test, num_round):\n",
    "    t0 = time.time()\n",
    "    model = lgb.train(params, lgbtrain_all, num_boost_round=num_round, feval=lgbm_smape)\n",
    "    test_preds = model.predict(X_test, num_iteration=num_round)\n",
    "    print('Total time taken in model training: ', (time.time()-t0)/60, 'minutes!')\n",
    "    return model, test_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "lgb_params = {'task':'train', 'boosting_type':'gbdt', 'objective':'regression', \n",
    "              'metric': {'mae'}, 'num_leaves': 10, 'learning_rate': 0.02, \n",
    "              'feature_fraction': 0.8, 'max_depth': 5, 'verbose': 0, \n",
    "              'num_boost_round':15000, 'nthread':-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'train',\n",
       " 'boosting_type': 'gbdt',\n",
       " 'objective': 'regression',\n",
       " 'metric': {'mae'},\n",
       " 'num_leaves': 10,\n",
       " 'learning_rate': 0.02,\n",
       " 'feature_fraction': 0.8,\n",
       " 'max_depth': 5,\n",
       " 'verbose': 0,\n",
       " 'nthread': -1}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Dataset at 0x24b0fb07d30>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbtrain_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  2.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  3.,  1., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [29., 88., 13., ...,  0.,  0.,  0.],\n",
       "       [30., 89., 13., ...,  0.,  0.,  0.],\n",
       "       [31., 90., 13., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[:,cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.lgbm_smape(preds, train_data)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "4192fdca974d3c4fade051fac2e87723f12983b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken in model training:  35.27308999300003 minutes!\n",
      "test_preds shape:(45000,)\n"
     ]
    }
   ],
   "source": [
    "# Training lgb model on whole data(train+val)\n",
    "lgb_model, test_preds = lgb_train(lgb_params, lgbtrain_all, test.loc[:,cols].values, model.best_iteration)\n",
    "print('test_preds shape:{}'.format(test_preds.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "23056dbbe715566d1cba5d1b6dafc3d9d972d128"
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "1aba1607a8f47480213035f7af77f9ac6f9c30c7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11.344051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14.128562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13.301148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15.347100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17.911739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      sales\n",
       "0   0  11.344051\n",
       "1   1  14.128562\n",
       "2   2  13.301148\n",
       "3   3  15.347100\n",
       "4   4  17.911739"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create submission\n",
    "sub = test.loc[:,['id','sales']]\n",
    "sub['sales'] = np.expm1(test_preds)\n",
    "sub['id'] = sub.id.astype(int)\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35eb0e52bff6541e1f948f6d43dab6a105818d67"
   },
   "source": [
    "## WaveNet Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "bb5af7ea2e8f0cb18f6fc30061ede9422634262b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "      <th>train_or_test</th>\n",
       "      <th>id</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_lag_91_ewm_0.5</th>\n",
       "      <th>sales_lag_98_ewm_0.5</th>\n",
       "      <th>sales_lag_105_ewm_0.5</th>\n",
       "      <th>sales_lag_112_ewm_0.5</th>\n",
       "      <th>sales_lag_119_ewm_0.5</th>\n",
       "      <th>sales_lag_126_ewm_0.5</th>\n",
       "      <th>sales_lag_182_ewm_0.5</th>\n",
       "      <th>sales_lag_364_ewm_0.5</th>\n",
       "      <th>sales_lag_546_ewm_0.5</th>\n",
       "      <th>sales_lag_728_ewm_0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store  item     sales train_or_test  id  dayofmonth  dayofyear  \\\n",
       "0 2013-01-01      1     1  2.639057         train NaN           1          1   \n",
       "1 2013-01-02      1     1  2.484907         train NaN           2          2   \n",
       "\n",
       "   dayofweek  month          ...            sales_lag_91_ewm_0.5  \\\n",
       "0          1      1          ...                             NaN   \n",
       "1          2      1          ...                             NaN   \n",
       "\n",
       "   sales_lag_98_ewm_0.5  sales_lag_105_ewm_0.5  sales_lag_112_ewm_0.5  \\\n",
       "0                   NaN                    NaN                    NaN   \n",
       "1                   NaN                    NaN                    NaN   \n",
       "\n",
       "   sales_lag_119_ewm_0.5  sales_lag_126_ewm_0.5  sales_lag_182_ewm_0.5  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "\n",
       "   sales_lag_364_ewm_0.5  sales_lag_546_ewm_0.5  sales_lag_728_ewm_0.5  \n",
       "0                    NaN                    NaN                    NaN  \n",
       "1                    NaN                    NaN                    NaN  \n",
       "\n",
       "[2 rows x 86 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_uuid": "8fe1b567de6709709f6310a760e284395510a5db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2013-01-01 00:00:00'), Timestamp('2018-03-31 00:00:00'))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.min(), df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae6542095a3558301661f2ccb6317094f14c7e17",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
